from model import googlenet
import torch
from torch.optim import SGD
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
from process_data import MalwareDataset
import os
import torchvision.transforms as transforms

# Set the configuration
cfg = {
    'gpu_usage': True,
    'seed': 42,
    'dataset_dir': 'data',
    'train_batch_size': 8,
    'num_workers': 4,
    'learning_rate': 1e-3,
    'n_epochs': 20,
    'save_dir': 'checkpoints',
    'log_dir': 'runs',
}


def train(cfg):
    device = torch.device('cuda' if cfg['gpu_usage'] else 'cpu')

    # Load data
    transform_train = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

    transform_val = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

    train_datasetset = MalwareDataset(os.path.join(cfg['dataset_dir'], 'train'), transform_train)
    train_loader = torch.utils.data.DataLoader(train_datasetset, batch_size=cfg['train_batch_size'], shuffle=True, num_workers=cfg['num_workers'])
    val_dataset = MalwareDataset(os.path.join(cfg['dataset_dir'], 'test'), transform_val)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=cfg['train_batch_size'], shuffle=False, num_workers=cfg['num_workers'])

    # Create the AutoEncoder model
    model = googlenet.to(device)
    model.train()  # Set model to training mode

    # Define the optimizer
    optimizer = SGD(model.parameters(), lr=cfg['learning_rate'], momentum=0.9, weight_decay=5e-4)

    # Define the loss function
    loss_fn = nn.CrossEntropyLoss()

    # Initialize TensorBoard SummaryWriter
    writer = SummaryWriter(log_dir=cfg['log_dir'])

    # Training loop
    n_epochs = cfg['n_epochs']
    for epoch in range(n_epochs):
        print(f"\nTraining epoch {epoch + 1}/{n_epochs}")
        print("-----------------------------------")

        # Training phase
        model.train()
        pbar = tqdm(train_loader, ncols=80, desc='Training')
        running_loss = 0.0
        train_num = 0
        for step, data in enumerate(pbar):
            inputs, targets = data['image'].to(device), data['label'].to(device)

            # Clear the old gradients
            optimizer.zero_grad()

            # Compute the forward pass
            outputs = model(inputs)

            # Compute loss and update weights
            loss = loss_fn(outputs, targets)
            loss.backward()  # Calculate gradients
            optimizer.step()  # Update weights

            # Aggregate loss
            running_loss += loss.item() * inputs.shape[0]
            train_num += inputs.shape[0]

        # Calculate and print average loss for the epoch
        train_loss = running_loss / train_num
        print(f"\tTrain loss: {train_loss:.4f}")

        # Validation phase
        model.eval()
        val_running_loss = 0.0
        val_num = 0
        with torch.no_grad():
            for inputs in val_loader:
                inputs, targets = data['image'].to(device), data['label'].to(device)

                # Compute the forward pass
                outputs = model(inputs)

                # Compute loss
                val_loss = loss_fn(outputs, targets)

                # Aggregate validation loss
                val_running_loss += val_loss.item() * inputs.shape[0]
                val_num += inputs.shape[0]

        # Calculate and print average validation loss for the epoch
        val_loss = val_running_loss / val_num
        print(f"\tValidation loss: {val_loss:.4f}")

        # Log average train and validation loss per epoch to TensorBoard
        writer.add_scalar('Loss/Train_epoch', train_loss, epoch)
        writer.add_scalar('Loss/Validation_epoch', val_loss, epoch)

        # Save model checkpoint
        torch.save(model.state_dict(), f"{cfg['save_dir']}/model_{epoch}.pth")

    writer.close()  # Close the writer after training is done


if __name__ == "__main__":
    train(cfg)
