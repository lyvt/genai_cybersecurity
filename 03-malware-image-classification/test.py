import os
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn import metrics
from process_data import MalwareDataset
from model import googlenet
import matplotlib.pyplot as plt
import seaborn as sns
import torchvision.transforms as transforms

# Configuration settings
cfg = {
    'gpu_usage': True,
    'seed': 42,
    'dataset_dir': 'data',
    'test_batch_size': 8,
    'save_dir': 'checkpoints',
}


def calculate_metrics(labels, predictions):
    """Calculate evaluation metrics for model performance."""
    accuracy = metrics.accuracy_score(labels, predictions)
    precision = metrics.precision_score(labels, predictions)
    recall = metrics.recall_score(labels, predictions)
    f1_score = metrics.f1_score(labels, predictions)

    # Generate the confusion matrix
    confusion_matrix = metrics.confusion_matrix(labels, predictions)

    # Plot the confusion matrix as a heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.savefig('confusion_matrix.pdf')
    plt.show()

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score
    }


def test(cfg):
    """Test the model using the specified configuration."""
    device = torch.device('cuda' if cfg['gpu_usage'] else 'cpu')

    # Load test data
    transform_test = transforms.Compose([transforms.ToTensor(),
                                         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
    test_dataset = MalwareDataset(os.path.join('dataset', 'test'), transform_test)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cfg['train_batch_size'], shuffle=False,
                                              num_workers=cfg['num_workers'])

    # Initialize the model
    model = googlenet.to(device)

    # Load the saved model checkpoint
    model_path = os.path.join(cfg['save_dir'], 'model_9.pth')
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))

    model = model.to(device)
    model.eval()

    labels = []
    predictions = []
    # Test loop
    with torch.no_grad():
        for x_batch, y_batch in tqdm(test_loader, desc='Testing'):
            x_batch = x_batch.to(device)

            # Forward pass through the model
            outputs = model(x_batch)
            _, y_predict = outputs.max(1)
            labels.extend(y_batch.tolist())
            predictions.extend(y_predict.cpu().tolist())

    # Calculate performance metrics
    performance_metrics = calculate_metrics(labels, predictions)

    return performance_metrics


if __name__ == "__main__":
    metrics = test(cfg)
    print(metrics)
